{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e408cfdc-13b8-4790-9b64-ca7ac09d054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tamim\\Desktop\\FYP\\Notes\\attendance_system\\Lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: insightface_models\\models\\buffalo_sc\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: insightface_models\\models\\buffalo_sc\\w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import face_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c3b5f0-bec1-4c5b-92aa-70a52e9de379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_rec.r.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471803be-7d97-4220-aa0b-3e45b0901051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f373de4-6c2b-43f4-a209-30c3e7c87f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_role</th>\n",
       "      <th>facial_features</th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angelina Jolie@Student</td>\n",
       "      <td>[2.720083e+23, 1.7162043, -2.720083e+23, 1.884...</td>\n",
       "      <td>Angelina Jolie</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morgan Freeman@Teacher</td>\n",
       "      <td>[0.0, 1.742713, 2.720083e+23, -1.7798407, 2.72...</td>\n",
       "      <td>Morgan Freeman</td>\n",
       "      <td>Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scarlett Johansson@Student</td>\n",
       "      <td>[2.720083e+23, 1.5663154, 4.172325e-08, -1.744...</td>\n",
       "      <td>Scarlett Johansson</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tamo@Student</td>\n",
       "      <td>[1.3741791, -0.72186685, -1.5866314, -0.408380...</td>\n",
       "      <td>tamo</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tamim@Student</td>\n",
       "      <td>[0.5978409, -1.1781582, -2.2906902, -0.5149337...</td>\n",
       "      <td>Tamim</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barack Obama@Teacher</td>\n",
       "      <td>[4.172325e-08, 1.862177, -107374184.0, -1.7645...</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Evans@Student</td>\n",
       "      <td>[107374184.0, 1.8050245, -2.720083e+23, -1.933...</td>\n",
       "      <td>Chris Evans</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name_role  \\\n",
       "0      Angelina Jolie@Student   \n",
       "1      Morgan Freeman@Teacher   \n",
       "2  Scarlett Johansson@Student   \n",
       "3                tamo@Student   \n",
       "4               Tamim@Student   \n",
       "5        Barack Obama@Teacher   \n",
       "6         Chris Evans@Student   \n",
       "\n",
       "                                     facial_features                name  \\\n",
       "0  [2.720083e+23, 1.7162043, -2.720083e+23, 1.884...      Angelina Jolie   \n",
       "1  [0.0, 1.742713, 2.720083e+23, -1.7798407, 2.72...      Morgan Freeman   \n",
       "2  [2.720083e+23, 1.5663154, 4.172325e-08, -1.744...  Scarlett Johansson   \n",
       "3  [1.3741791, -0.72186685, -1.5866314, -0.408380...                tamo   \n",
       "4  [0.5978409, -1.1781582, -2.2906902, -0.5149337...               Tamim   \n",
       "5  [4.172325e-08, 1.862177, -107374184.0, -1.7645...        Barack Obama   \n",
       "6  [107374184.0, 1.8050245, -2.720083e+23, -1.933...         Chris Evans   \n",
       "\n",
       "      role  \n",
       "0  Student  \n",
       "1  Teacher  \n",
       "2  Student  \n",
       "3  Student  \n",
       "4  Student  \n",
       "5  Teacher  \n",
       "6  Student  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'academy:register'\n",
    "retrive_dict= face_rec.r.hgetall(name)\n",
    "retrive_series = pd.Series(retrive_dict)\n",
    "retrive_series = retrive_series.apply(lambda x: np.frombuffer(x,dtype=np.float32))\n",
    "index = retrive_series.index\n",
    "index = list(map(lambda x: x.decode(), index))\n",
    "retrive_series.index = index\n",
    "retrive_df = retrive_series.to_frame().reset_index()\n",
    "retrive_df.columns = ['name_role','facial_features']\n",
    "retrive_df[['name','role']] = retrive_df['name_role'].apply(lambda x: x.split('@')).apply(pd.Series)\n",
    "retrive_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ad338-63b2-44af-b736-967b3abf4f66",
   "metadata": {},
   "source": [
    "### step2:Getting Real-Time predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582885d0-cf89-45be-b964-66552870447a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'x_list' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m pred_frame \u001b[38;5;241m=\u001b[39m \u001b[43mface_rec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrive_df\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacial_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m,frame)\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediciton\u001b[39m\u001b[38;5;124m'\u001b[39m,pred_frame)\n",
      "File \u001b[1;32m~\\Desktop\\FYP\\Notes\\2_fast_recognition_system\\face_rec.py:72\u001b[0m, in \u001b[0;36mface_prediction\u001b[1;34m(test_image, dataframe, feature_column, name_role, thresh)\u001b[0m\n\u001b[0;32m     69\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m ]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# testing with both the dataset and compressed dataset which obtained in below cell\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#person_name, person_role = ml_search_algorithm(dataframe,'facial_features',test_vector=embeddings,name_role=['name','role'],thresh=0.5)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m person_name, person_role \u001b[38;5;241m=\u001b[39m \u001b[43mml_search_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeature_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname_role\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_role\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m person_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     77\u001b[0m     color \u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m) \u001b[38;5;66;03m# bgr\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\FYP\\Notes\\2_fast_recognition_system\\face_rec.py:33\u001b[0m, in \u001b[0;36mml_search_algorithm\u001b[1;34m(dataframe, feature_column, test_vector, name_role, thresh)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mml_search_algorithm\u001b[39m(dataframe, feature_column, test_vector,name_role\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m],thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#cosine similarity base search algorithm\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Assuming X_list is a list of embedding vectors\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(\u001b[43mx_list\u001b[49m)  \u001b[38;5;66;03m# Stack all embeddings into a 2D array\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Ensure the test_vector is reshaped properly for cosine similarity\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     similar \u001b[38;5;241m=\u001b[39m pairwise\u001b[38;5;241m.\u001b[39mcosine_similarity(X, test_vector\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'x_list' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)  # default , # 1 for external camera\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    pred_frame = face_rec.face_prediction(frame, retrive_df,'facial_features', ['name','role'],thresh=0.5)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('prediciton',pred_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27: # if i press esc button this condition will get trigged\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c10630-fbf7-4c9e-93c7-84956ae5c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40ce81-44b1-4ea3-a6c8-1c2ac744a884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
